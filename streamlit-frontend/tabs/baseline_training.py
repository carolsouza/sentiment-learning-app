import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots


def render_baseline_training_tab(api_client, api_status):
    """Renderiza a tab de Baseline Training"""
    st.header("ðŸš€ Treinamento do Modelo Baseline")

    if 'dataset_info' in st.session_state:
        _render_training_interface(api_client, api_status)
    else:
        _render_no_dataset_message()


def _render_no_dataset_message():
    """Renderiza mensagem quando nÃ£o hÃ¡ dataset"""
    st.warning("ðŸ“ FaÃ§a upload de um dataset primeiro para habilitar o treinamento.")
    st.info("ðŸ’¡ VÃ¡ para a aba 'Dataset Upload' para fazer upload do seu arquivo CSV.")

    st.markdown("---")
    st.subheader("ðŸ“‹ Sobre o Modelo Baseline")
    st.markdown("""
    **Naive Bayes + TF-IDF** Ã© um modelo simples e eficaz para anÃ¡lise de sentimento:

    - **Naive Bayes**: Classificador probabilÃ­stico baseado no teorema de Bayes
    - **TF-IDF**: Term Frequency-Inverse Document Frequency para vetorizaÃ§Ã£o de texto
    - **RÃ¡pido**: Treinamento e prediÃ§Ã£o muito rÃ¡pidos
    - **InterpretÃ¡vel**: FÃ¡cil de entender e explicar
    - **Baseline**: Ponto de partida para comparar com modelos mais complexos
    """)


def _render_training_interface(api_client, api_status):
    """Renderiza a interface principal de treinamento"""
    dataset_info = st.session_state['dataset_info']

    # InformaÃ§Ãµes do dataset
    st.success(f"âœ… Dataset carregado: {dataset_info['filename']} ({dataset_info['size_mb']:.1f}MB)")

    # Calcula estatÃ­sticas se necessÃ¡rio
    _calculate_dataset_statistics(dataset_info)

    # Layout em duas colunas
    col1, col2 = st.columns([2, 1])

    with col1:
        _render_training_form(api_client, api_status)

    with col2:
        _render_training_info_panel()


def _calculate_dataset_statistics(dataset_info):
    """Calcula estatÃ­sticas do dataset se necessÃ¡rio"""
    if 'dataset_stats' not in st.session_state:
        with st.spinner("ðŸ“Š Calculando estatÃ­sticas do dataset..."):
            try:
                df_info = dataset_info['preview_df']

                # Filtra apenas scores vÃ¡lidos (1,2,4,5)
                df_filtered = df_info[df_info["score"].isin([1, 2, 4, 5])].copy()
                total_samples = len(df_filtered)

                # Conta amostras por classe
                df_filtered["sentiment"] = df_filtered["score"].apply(
                    lambda x: "negativo" if x in [1, 2] else "positivo"
                )
                neg_count = len(df_filtered[df_filtered["sentiment"] == "negativo"])
                pos_count = len(df_filtered[df_filtered["sentiment"] == "positivo"])

                # Salva estatÃ­sticas no session state
                st.session_state['dataset_stats'] = {
                    'total_samples': total_samples,
                    'neg_count': neg_count,
                    'pos_count': pos_count
                }

            except Exception as e:
                st.error(f"Erro ao processar informaÃ§Ãµes do dataset: {e}")
                st.session_state['dataset_stats'] = {
                    'total_samples': 10000,
                    'neg_count': 0,
                    'pos_count': 0
                }


def _render_training_form(api_client, api_status):
    """Renderiza o formulÃ¡rio de treinamento"""
    # Usa estatÃ­sticas jÃ¡ calculadas
    stats = st.session_state['dataset_stats']
    total_samples = stats['total_samples']
    neg_count = stats['neg_count']
    pos_count = stats['pos_count']

    # InformaÃ§Ãµes do dataset
    st.info(f"ðŸ“Š {total_samples} amostras vÃ¡lidas ({neg_count} negativos, {pos_count} positivos)")

    # Verifica se estÃ¡ treinando para evitar duplicaÃ§Ã£o do formulÃ¡rio
    if 'training_in_progress' not in st.session_state:
        st.session_state['training_in_progress'] = False

    if not st.session_state['training_in_progress']:
        _render_training_parameters_form(api_client, api_status, total_samples, neg_count, pos_count)
    else:
        _render_training_in_progress()


def _render_training_parameters_form(api_client, api_status, total_samples, neg_count, pos_count):
    """Renderiza o formulÃ¡rio de parÃ¢metros de treinamento"""
    with st.form("baseline_training_form"):
        st.subheader("âš™ï¸ ConfiguraÃ§Ãµes do Treinamento")

        # SeÃ§Ã£o de parÃ¢metros do dataset
        st.markdown("**ðŸ“Š ParÃ¢metros do Dataset:**")
        max_samples = st.number_input(
            "MÃ¡ximo de amostras",
            min_value=100,
            max_value=total_samples,
            value=min(50000, total_samples),
            step=1000,
            help=f"Quantidade mÃ¡xima de amostras para usar no treinamento (mÃ¡ximo disponÃ­vel: {total_samples})"
        )

        balance_data = st.checkbox(
            "Balancear classes",
            value=True,
            help="Equilibra a quantidade de amostras positivas e negativas"
        )

        # Aviso sobre balanceamento
        _render_balance_warnings(balance_data, neg_count, pos_count, max_samples)

        st.markdown("---")

        # SeÃ§Ã£o de parÃ¢metros do modelo
        st.markdown("**ðŸ¤– ParÃ¢metros do Modelo:**")

        col_param1, col_param2 = st.columns(2)

        with col_param1:
            test_size = st.slider(
                "Tamanho do conjunto de teste (%)",
                min_value=10,
                max_value=50,
                value=20,
                step=5,
                help="Porcentagem dos dados que serÃ¡ usado para teste"
            ) / 100

            max_features = st.selectbox(
                "MÃ¡ximo de features TF-IDF",
                [1000, 5000, 10000, 20000],
                index=1,
                help="NÃºmero mÃ¡ximo de features para o vetorizador TF-IDF"
            )

        with col_param2:
            experiment_name = st.text_input(
                "Nome do Experimento",
                value="sentiment_analysis_baseline",
                help="Nome para organizar os experimentos no MLflow"
            )

            # Mostra distribuiÃ§Ã£o final
            if balance_data and neg_count > 0 and pos_count > 0:
                min_class = min(neg_count, pos_count)
                final_samples = min(min_class * 2, max_samples)
                st.metric("Amostras finais estimadas", final_samples)
            else:
                final_samples = min(total_samples, max_samples)
                st.metric("Amostras finais estimadas", final_samples)

        st.markdown("---")

        # BotÃ£o de treinamento
        col_btn1, col_btn2, col_btn3 = st.columns([1, 2, 1])
        with col_btn2:
            submit_training = st.form_submit_button(
                "ðŸš€ Iniciar Treinamento Baseline",
                type="primary",
                disabled=not api_status,
                use_container_width=True
            )

        if submit_training:
            _handle_training_submission(
                api_client, api_status, max_samples, balance_data,
                test_size, max_features, experiment_name
            )


def _render_balance_warnings(balance_data, neg_count, pos_count, max_samples):
    """Renderiza avisos sobre balanceamento"""
    if balance_data and neg_count > 0 and pos_count > 0:
        min_class = min(neg_count, pos_count)
        max_balanced_samples = min_class * 2

        if max_samples > max_balanced_samples:
            st.warning(f"âš ï¸ Com balanceamento, mÃ¡ximo utilizÃ¡vel: {max_balanced_samples} amostras "
                     f"({min_class} de cada classe)")

    elif balance_data and (neg_count == 0 or pos_count == 0):
        st.error("âŒ NÃ£o Ã© possÃ­vel balancear: apenas uma classe disponÃ­vel")
        st.info("ðŸ’¡ Desmarque 'Balancear classes' para usar todos os dados")


def _render_training_in_progress():
    """Renderiza interface durante o treinamento"""
    st.info("ðŸ¤– Treinamento em progresso...")
    st.warning("â³ Aguarde a conclusÃ£o do treinamento atual.")

    col1, col2 = st.columns(2)
    with col1:
        if st.button("ðŸ”„ Atualizar Status", use_container_width=True):
            st.session_state['training_in_progress'] = False
            st.rerun()

    with col2:
        if st.button("âŒ Cancelar Treinamento", use_container_width=True):
            st.session_state['training_in_progress'] = False
            st.warning("Treinamento cancelado pelo usuÃ¡rio")
            st.rerun()


def _render_training_info_panel():
    """Renderiza painel de informaÃ§Ãµes sobre o treinamento"""
    st.subheader("ðŸ“‹ Sobre o Treinamento")

    st.markdown("""
    **Processo de Treinamento:**

    1. **PreparaÃ§Ã£o**: Filtrar e balancear dados
    2. **VetorizaÃ§Ã£o**: Converter texto em features TF-IDF
    3. **DivisÃ£o**: Separar treino/teste
    4. **Treinamento**: Treinar Naive Bayes
    5. **AvaliaÃ§Ã£o**: Calcular mÃ©tricas
    6. **Registro**: Salvar no MLflow
    """)

    st.markdown("---")

    # Ãšltimos resultados
    if 'last_training_result' in st.session_state:
        st.markdown("**ðŸ† Ãšltimo Treinamento:**")
        result = st.session_state['last_training_result']

        if result.get("success", False):
            metrics = result.get("metrics", {})
            st.success(f"âœ… AcurÃ¡cia: {metrics.get('accuracy', 0):.3f}")
            st.info(f"ðŸ†” Run: {result.get('run_id', '')}")
        else:
            st.error("âŒ Ãšltimo treinamento falhou")


def _handle_training_submission(api_client, api_status, max_samples, balance_data, test_size, max_features, experiment_name):
    """Manipula o envio do formulÃ¡rio de treinamento"""
    # Marca como treinando para evitar duplicaÃ§Ã£o do formulÃ¡rio
    st.session_state['training_in_progress'] = True

    if not api_status:
        st.error("API nÃ£o estÃ¡ disponÃ­vel. Verifique se o serviÃ§o estÃ¡ rodando.")
        st.session_state['training_in_progress'] = False
    else:
        with st.spinner("ðŸ¤– Treinando modelo... Isso pode levar alguns minutos."):
            # Prepara request para a API usando o file_path da API
            training_request = {
                "dataset_path": st.session_state['dataset_info']['file_path'],
                "max_samples": max_samples,
                "balance_data": balance_data,
                "test_size": test_size,
                "max_features": max_features,
                "experiment_name": experiment_name
            }

            # Chama a API
            result = api_client.train_model(training_request)

        # Exibe resultados
        _display_training_results(result)

        # Marca treinamento como concluÃ­do
        st.session_state['training_in_progress'] = False


def _display_training_results(result):
    """Exibe os resultados do treinamento"""
    if result.get("success", False):
        st.success("âœ… Modelo treinado com sucesso!")

        # Salva resultado na sessÃ£o
        st.session_state['last_training_result'] = result

        # Exibe mÃ©tricas em cards
        st.subheader("ðŸ“Š Resultados do Treinamento")

        metrics = result.get("metrics", {})
        col_metric1, col_metric2, col_metric3, col_metric4 = st.columns(4)

        with col_metric1:
            st.metric("ðŸŽ¯ AcurÃ¡cia", f"{metrics.get('accuracy', 0):.3f}")
        with col_metric2:
            st.metric("ðŸ“ˆ F1-Score", f"{metrics.get('f1_score', 0):.3f}")
        with col_metric3:
            st.metric("ðŸ” PrecisÃ£o", f"{metrics.get('precision', 0):.3f}")
        with col_metric4:
            st.metric("ðŸ“Š Recall", f"{metrics.get('recall', 0):.3f}")
            
        # InformaÃ§Ãµes sobre balanceamento
        if 'balancing_info' in result:
            _render_balancing_info(result['balancing_info'])

        # GrÃ¡ficos detalhados dos resultados
        _render_detailed_metrics_charts(metrics, result)

        # InformaÃ§Ãµes do experimento
        st.info(f"ðŸ“‹ Experimento ID: {result.get('experiment_id', '')}")
        st.info(f"ðŸƒ Run ID: {result.get('run_id', '')}")

    else:
        st.error(f"âŒ Erro no treinamento: {result.get('message', 'Erro desconhecido')}")

        # SugestÃµes para resoluÃ§Ã£o
        st.markdown("**ðŸ’¡ PossÃ­veis soluÃ§Ãµes:**")
        st.write("â€¢ Verifique se a API estÃ¡ rodando")
        st.write("â€¢ Confirme se o dataset estÃ¡ vÃ¡lido")
        st.write("â€¢ Tente reduzir o nÃºmero de amostras")
        st.write("â€¢ Verifique os logs da API para mais detalhes")


def _render_detailed_metrics_charts(metrics, result):
    """Renderiza grÃ¡ficos detalhados das mÃ©tricas do modelo"""
    st.markdown("---")
    st.subheader("ðŸ“ˆ AnÃ¡lise Detalhada do Modelo")

    # Cria tabs para diferentes visualizaÃ§Ãµes
    chart_tab1, chart_tab2, chart_tab3 = st.tabs([
        "ðŸ“Š MÃ©tricas Gerais",
        "ðŸŽ¯ Matriz de ConfusÃ£o",
        "ðŸ“ˆ Performance por Classe"
    ])

    with chart_tab1:
        _render_general_metrics_chart(metrics)

    with chart_tab2:
        _render_confusion_matrix_chart(result)

    with chart_tab3:
        _render_class_performance_chart(result)


def _render_general_metrics_chart(metrics):
    """GrÃ¡fico de radar com as mÃ©tricas gerais"""
    st.markdown("**ðŸŽ¯ VisÃ£o Geral das MÃ©tricas**")

    # Dados para o grÃ¡fico de radar
    metrics_names = ['AcurÃ¡cia', 'PrecisÃ£o', 'Recall', 'F1-Score']
    metrics_values = [
        metrics.get('accuracy', 0),
        metrics.get('precision', 0),
        metrics.get('recall', 0),
        metrics.get('f1_score', 0)
    ]

    # GrÃ¡fico de radar
    fig = go.Figure()

    fig.add_trace(go.Scatterpolar(
        r=metrics_values,
        theta=metrics_names,
        fill='toself',
        name='Modelo Baseline',
        line_color='blue',
        fillcolor='rgba(0, 100, 255, 0.1)'
    ))

    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 1]
            )),
        showlegend=True,
        title="Radar de Performance do Modelo",
        height=400
    )

    st.plotly_chart(fig, use_container_width=True)

    # InterpretaÃ§Ã£o das mÃ©tricas
    col1, col2 = st.columns(2)
    with col1:
        st.info("**ðŸ“– InterpretaÃ§Ã£o:**")
        st.write(f"â€¢ **AcurÃ¡cia**: {metrics.get('accuracy', 0):.1%} de prediÃ§Ãµes corretas")
        st.write(f"â€¢ **PrecisÃ£o**: {metrics.get('precision', 0):.1%} dos positivos preditos sÃ£o corretos")

    with col2:
        st.write(f"â€¢ **Recall**: {metrics.get('recall', 0):.1%} dos positivos reais foram encontrados")
        st.write(f"â€¢ **F1-Score**: {metrics.get('f1_score', 0):.1%} harmonia entre precisÃ£o e recall")


def _render_confusion_matrix_chart(result):
    """Matriz de confusÃ£o com dados reais do MLflow"""
    st.markdown("**ðŸŽ¯ Matriz de ConfusÃ£o**")

    # Usa dados reais da matriz de confusÃ£o
    if 'confusion_matrix' in result:
        cm = result['confusion_matrix']
    else:
        st.warning("âš ï¸ Dados da matriz de confusÃ£o nÃ£o disponÃ­veis")
        return

    fig = go.Figure(data=go.Heatmap(
        z=cm,
        x=['Predito: Negativo', 'Predito: Positivo'],
        y=['Real: Negativo', 'Real: Positivo'],
        colorscale='Blues',
        text=cm,
        texttemplate="%{text}",
        textfont={"size": 20},
        showscale=True
    ))

    fig.update_layout(
        title="Matriz de ConfusÃ£o",
        xaxis_title="PrediÃ§Ã£o",
        yaxis_title="Valor Real",
        height=400
    )

    st.plotly_chart(fig, use_container_width=True)

    # ExplicaÃ§Ã£o da matriz
    st.info("""
    **ðŸ“– Como interpretar:**
    - **Diagonal principal**: PrediÃ§Ãµes corretas
    - **Diagonal secundÃ¡ria**: Erros do modelo
    - **Valores maiores na diagonal = melhor modelo**
    """)


def _render_class_performance_chart(result):
    """Performance por classe com dados reais do MLflow"""
    st.markdown("**ðŸ“ˆ Performance por Classe**")

    # Extrai mÃ©tricas por classe dos dados reais
    if 'class_metrics' in result:
        class_report = result['class_metrics']

        # Extrai apenas as classes (remove macro avg, weighted avg, etc)
        class_data = {}
        for class_name, class_metrics in class_report.items():
            if isinstance(class_metrics, dict) and class_name not in ['accuracy', 'macro avg', 'weighted avg']:
                class_data[class_name] = {
                    'precision': class_metrics.get('precision', 0),
                    'recall': class_metrics.get('recall', 0),
                    'f1_score': class_metrics.get('f1-score', 0)
                }
    else:
        st.warning("âš ï¸ Dados de mÃ©tricas por classe nÃ£o disponÃ­veis")
        return

    # Prepara dados para o grÃ¡fico
    classes = list(class_data.keys())
    precision_vals = [class_data[cls]['precision'] for cls in classes]
    recall_vals = [class_data[cls]['recall'] for cls in classes]
    f1_vals = [class_data[cls]['f1_score'] for cls in classes]

    # GrÃ¡fico de barras agrupadas
    fig = go.Figure()

    fig.add_trace(go.Bar(
        name='PrecisÃ£o',
        x=classes,
        y=precision_vals,
        marker_color='lightblue'
    ))

    fig.add_trace(go.Bar(
        name='Recall',
        x=classes,
        y=recall_vals,
        marker_color='lightgreen'
    ))

    fig.add_trace(go.Bar(
        name='F1-Score',
        x=classes,
        y=f1_vals,
        marker_color='lightcoral'
    ))

    fig.update_layout(
        title='MÃ©tricas por Classe',
        xaxis_title='Classe',
        yaxis_title='Score',
        barmode='group',
        height=400,
        yaxis=dict(range=[0, 1])
    )

    st.plotly_chart(fig, use_container_width=True)

    # Tabela com valores exatos
    df_class = pd.DataFrame(class_data).T
    df_class = df_class.round(3)
    st.dataframe(df_class, use_container_width=True)


def _render_balancing_info(balancing_info):

    was_balanced = balancing_info.get('was_balanced', False)
    neg_count = balancing_info.get('final_negative_count', 0)
    pos_count = balancing_info.get('final_positive_count', 0)
    is_perfectly_balanced = balancing_info.get('is_perfectly_balanced', False)

    col1, col2 = st.columns(2)

    with col1:
        st.metric("âž– Amostras Negativas", neg_count)

    with col2:
        st.metric("âž• Amostras Positivas", pos_count)

    # Status do balanceamento
    if was_balanced:
        if is_perfectly_balanced:
            st.success("âœ… **Balanceamento Perfeito**: Dataset perfeitamente balanceado 50/50!")
        else:
            ratio = max(neg_count, pos_count) / max(min(neg_count, pos_count), 1)
            st.warning(f"âš ï¸ **Balanceamento Limitado**: ProporÃ§Ã£o {ratio:.1f}:1. "
                      f"Pode ser devido Ã  limitaÃ§Ã£o de amostras disponÃ­veis em uma das classes.")

    else:
        st.info("â„¹ï¸ **Sem Balanceamento**: Dataset usado na proporÃ§Ã£o original.")

        total = neg_count + pos_count
        neg_percent = (neg_count / total) * 100 if total > 0 else 0
        pos_percent = (pos_count / total) * 100 if total > 0 else 0

        st.write(f"â€¢ **Negativos**: {neg_count} amostras ({neg_percent:.1f}%)")
        st.write(f"â€¢ **Positivos**: {pos_count} amostras ({pos_percent:.1f}%)")
